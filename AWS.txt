Encrypt unencrypted EBS volume / RDS database

* create a snapshot, create new encrypted EBS volume from it
* copy it into an encrypted one, create new volume/db from it

Capacity Reservations

Amazon EC2 on-demand Capacity Reservations enable you to create and manage
reserved capacity on Amazon EC2 without any long-term commitment or fixed
terms. This can be very beneficial if you regularly face
InsufficientInstanceCapacity errors when AWS doesn't have enough available
on-demand capacity while starting or launching an EC2 instance.

For cluster placement groups, capacity also means running on the 'same'
hardware and that hardware needs to be reserved.
Use Reserved Instances instead if you want to commit to 1 or 3 years

Placement groups

  cluster -  low latency,  low availability: share hardware => same EC2 type
partition -  avg latency,  avg availability: spread partitions across hardware, 7 partitions per AZ
   spread - high latency, high availability: multi AZ, 7 instances in different racks in 1 group per AZ, diff hw allows for different EC2 types

Elastic Load Balancer

ALB: distribute load based on protocol,  port and HTTP headers, ...
NLB: distribute load based on protocol & port only
     define static IPs (per AZ) for the NLB (so customers can whitelist us)

* dispatch requests to target groups based on routes, query string, headers, IPs (ALB)
                                           /url1 -> tg1
                          /url2, one.example.com -> tg2
  two.example.com, ?platform=mobile, HTTP header -> tg3

  then spread load across multiple or single (e.g containers) host(s) in the
  target group based on health checks (port + route) => seamless handling of
  downstream instances failures

* SSL termination

IAM principal = user or role

Service-Linked Role:
only a specific service can use this role vs a regular role which can be used by all services/users

  SG - statefull, if one way is allowed then the return way is automatically allowed
NACL - stateless, both ways are always evaluated

SG
EC2, ELB, EFS, RDS, ElastiCache

A private host behind NAT "can't" be contacted, for that you need NAT traversal:
Also known as UDP encapsulation, it allows traffic to get to the specified
destination which doesn't have a public IP address. In a S2S VPN connection, a
CGW behind NAT needs this enabled

CloudFront
   cache + S3 or http/rtmp endpoint as origin

Global Accelerator: accelerates APPS (no S3) only
no cache + no http endpoint (VOIP, IoT, ...)

kinesis DS (pub/sub)

                      SDK, KPL                SDK, KCL
1 MB/s or 1000 msg/s per shard - Kinesis DS - 2 MB/s per shard per       all (shared)
                                              2 MB/s per shard per consummer (enhanced fanout)

A persistent spot request is like an ASG. It will keep spawning instances till the end of its validity period.

1 CPU = multiple cores = multiple threads. vCPU is the total of threads.

EBS
                            max
gp3 | 1 GiB to 16 TiB |  16 000  iops | 1000 MiB/s | not multi-attach
io2 | 4 GiB to 16 TiB |  32 000 piops |            |
    |                 |  64 000 piops |            | if Nitro
    | 4 GiB to 64 TiB | 256 000 piops |            | if block express

ASG

Use golden AMI so updates, app install, ... take less time => we can use a smaller cooldown period

In AWS there is a network cost when data moves between AZs,
but not for RDS read replicas within the same region (only cross-region)

Aurora DB
writer + reader OR custom endpoint

ElastiCache
* requires heavy code changes
* no IAM auth, redis auth or Memcached SASL
redis: sorted sets for real-time leaderboards

Route 53

Alias: CNAME to 1 managed AWS resource (no EC2!)
       no TTL, can point to zone apex, free

record with multiple A values -> the client will choose at random (client side LB)

health checks: only return IPs for healthy resources
               e.g give me a healthy ALB, then target group health check to give me a healthy EC2 instance

routing policies:

- simple (no health checks)
- weighted
  weight.example.com 70 - 7.8.9.1
  weight.example.com 30 - 3.4.5.6
  weight.example.com 10 - 1.1.8.8
- latency
- failover (primary active / secondary passive)
- geolocation (default IP mandatory)
- geoproximity (traffic flow, bias -1 .. 99)
- multi-value (again client side LB but with health checks, return up to 8 IPs)

GoDaddy registrar with Route 53 DNS:
register domain with GoDaddy but specify custom nameservers (AWS ones) where the records will be defined

http statefullness can be achieved with:
* ELB stickiness (session/client affinity)
* cookies stored on EC2 instances or sent by user (web cookies)
* single session_id cookie sent by client, session info stored in ElastiCache

Beanstalk
dev centric view, infrastructure is transparent
PaaS: versioned application / environment (dev,test,prod) +    web tier (ELB -> ASG) or
                                                            worker tier (SQS <- ASG)

S3 (web URL - http/https)

3_500 PUT req/s per prefix
5_500 GET req/s per prefix, both limited by KMS (5_500, 10_000, 30_000 req/s based on region, increase with quotas)

naming: 3-63 -> no upper, _, IP; start with [a-z0-9]
        s3://bucket-name/folder-1/folder-2/my-image.jgp > max 5TB, multi-part upload if >5GB
                         prefix          + name = key

with versioning enabled, removal of an object adds a 'delete marker'.
deleting a specific version or a 'delete marker' one is permanent.

storage classes:
        std, std-ia -> min 30 days
intelligent tiering -> small monthly monitoring and auto-tiering fee
     amazon glacier -> archives go in vaults
                       90 days min, 180 for deep archive
retrieval cost per GB for all but std/intelligent

lifecycle rules
- transition actions
- expiration actions (deletion)

replication isn't chained:
A -> B -> C doesn't mean A -> C.
objects in B replicated from A aren't considered new. only explicit new ones will be replicated to C

encryption:
SSE-S3  = "x-amz-server-side-encryption": "AES256",  in header
SSE-KMS = "x-amz-server-side-encryption": "aws:kms", in header
SSE-C   =                                       key, in header (https mandatory)
CSE     = client side encryption

the default encryption setting will be applied only to non-encrypted objects,
meaning that if an object is already encrypted (e.g via bucket policy) it won't be altered.

block all public access
* to buckets/objects                 via new ACLs
* to buckets/objects                 via ANY ACLs (existing ones too)
* to buckets/objects                 via new public bucket or access point policies
* to buckets/objects + cross-account via ANY public bucket or access point policies

pre-signed URLs
generate GET ones with cli, GET/PUT ones with SDK (creator's get/put permissions inherited by users)
valid for a limited time only (3600s by default)

note: with CloudFront in front of our bucket, we must use CloudFront signed
URLs for single files or signed cookies for multiple files because bucket
access is restricted to the OAI.

CORS: cross-origin resource sharing (web browser security mechanism)
get index.html                         from www.example.com (origin - protocol://domain:port),
    index.html tries to get a resource from   net.games.com (cross-origin)
                                              net.games.com needs to send headers Access-Control-Allow-Origin:  https://www.example.com
                                                                                  Access-Control-Allow-Methods: GET, ...
